{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "0bf057ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import root_mean_squared_error as rmse\n",
    "from alive_progress import alive_bar\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Load the data\n",
    "train_data = pd.read_csv(\"../tmp/filtered_data.csv\")\n",
    "# test_data = pd.read_parquet(\"data/test_data.parquet\")\n",
    "test_data = pd.read_parquet(\"val_Y.parquet\")\n",
    "\n",
    "# Convert expiry to datetime if it's not already\n",
    "if train_data[\"expiry\"].dtype != \"datetime64[ns]\":\n",
    "    train_data[\"expiry\"] = pd.to_datetime(train_data[\"expiry\"])\n",
    "\n",
    "# Get the target expiry date\n",
    "target_date = pd.Timestamp(\"2025-05-08\").date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "50729275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training data shape: 178340\n",
      "New training data shape: (154587, 97)\n",
      "Validation data shape: (23753, 97)\n",
      "Test data shape: (23753, 97)\n"
     ]
    }
   ],
   "source": [
    "# Filter rows with the specified expiry date\n",
    "expiry_filter = train_data[\"expiry\"].dt.date == target_date\n",
    "target_rows = train_data[expiry_filter]\n",
    "\n",
    "# Get indices of rows to be used for validation (50% of the rows with target expiry)\n",
    "validation_indices = target_rows.sample(frac=0.3, random_state=43).index\n",
    "\n",
    "# Create validation set\n",
    "val_data = train_data.loc[validation_indices].copy()\n",
    "\n",
    "# Remove validation data from training set\n",
    "train_data = train_data.drop(validation_indices)\n",
    "\n",
    "# Print shapes to confirm\n",
    "print(f\"Original training data shape: {len(train_data) + len(val_data)}\")\n",
    "print(f\"New training data shape: {train_data.shape}\")\n",
    "print(f\"Validation data shape: {val_data.shape}\")\n",
    "print(f\"Test data shape: {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "b3e42366",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_Y = pd.read_parquet(\"val_Y.parquet\")\n",
    "sample_val = pd.read_parquet(\"sample_val.parquet\")\n",
    "sample_val_matching = pd.read_csv(\"output/matching.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "30684027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def get_prediction(target_col):\n",
    "    # Prepare features and target\n",
    "    feature_cols = ['underlying'] + [col for col in train_data.columns if col.startswith('X')]\n",
    "    X = train_data[feature_cols]\n",
    "    y = train_data[target_col]\n",
    "\n",
    "    # Split into train and validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train XGBoost model\n",
    "    xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    "  )\n",
    "\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = xgb_model.predict(X_val)\n",
    "\n",
    "    # Calculate RMSE\n",
    "    rmse_score = rmse(y_val, y_pred)\n",
    "    print(f\"RMSE for {target_col}: {rmse_score:.6f}\")\n",
    "\n",
    "    # Predict on validation data\n",
    "    val_features = val_data[feature_cols]\n",
    "    val_predictions = xgb_model.predict(val_features)\n",
    "\n",
    "    print(f\"Predictions shape: {val_predictions.shape}\")\n",
    "    print(f\"Sample predictions: {val_predictions[:5]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "c689baf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for call_iv_25000: 0.096926\n",
      "Predictions shape: (23753,)\n",
      "Sample predictions: [0.17303367 0.14510675 0.18535015 0.22857085 0.23733236]\n"
     ]
    }
   ],
   "source": [
    "get_prediction(\"call_iv_25000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "9407dfc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expiry mapping: {Timestamp('2025-04-24 00:00:00'): 0, Timestamp('2025-04-30 00:00:00'): 1, Timestamp('2025-05-08 00:00:00'): 2}\n",
      "Train data expiry values: [0, 1, 2]\n",
      "Val data expiry values: [2]\n"
     ]
    }
   ],
   "source": [
    "# Convert expiry dates to integer labels\n",
    "unique_expiries = sorted(train_data['expiry'].unique())\n",
    "expiry_mapping = {expiry: i for i, expiry in enumerate(unique_expiries)}\n",
    "\n",
    "# Apply mapping to train_data\n",
    "train_data['expiry'] = train_data['expiry'].map(expiry_mapping)\n",
    "\n",
    "# Apply same mapping to val_data\n",
    "val_data['expiry'] = val_data['expiry'].map(expiry_mapping)\n",
    "\n",
    "print(f\"Expiry mapping: {expiry_mapping}\")\n",
    "print(f\"Train data expiry values: {sorted(train_data['expiry'].unique())}\")\n",
    "print(f\"Val data expiry values: {sorted(val_data['expiry'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "f786fcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_val.expiry = 2\n",
    "val_Y.expiry = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "91da4f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>underlying</th>\n",
       "      <th>expiry</th>\n",
       "      <th>call_iv_23500</th>\n",
       "      <th>call_iv_23600</th>\n",
       "      <th>call_iv_23700</th>\n",
       "      <th>call_iv_23800</th>\n",
       "      <th>call_iv_23900</th>\n",
       "      <th>call_iv_24000</th>\n",
       "      <th>call_iv_24100</th>\n",
       "      <th>...</th>\n",
       "      <th>X32</th>\n",
       "      <th>X33</th>\n",
       "      <th>X34</th>\n",
       "      <th>X35</th>\n",
       "      <th>X36</th>\n",
       "      <th>X37</th>\n",
       "      <th>X38</th>\n",
       "      <th>X39</th>\n",
       "      <th>X40</th>\n",
       "      <th>X41</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158881</th>\n",
       "      <td>1746590742000000000</td>\n",
       "      <td>24433.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.435793</td>\n",
       "      <td>0.409610</td>\n",
       "      <td>0.383775</td>\n",
       "      <td>0.356050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.022656</td>\n",
       "      <td>0.006262</td>\n",
       "      <td>2.553592e+06</td>\n",
       "      <td>-0.001931</td>\n",
       "      <td>2.372125</td>\n",
       "      <td>0.068108</td>\n",
       "      <td>-1.522534e+06</td>\n",
       "      <td>-3.048516e+06</td>\n",
       "      <td>1.254699e+06</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117518</th>\n",
       "      <td>1746176782000000000</td>\n",
       "      <td>24285.5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.187751</td>\n",
       "      <td>0.178467</td>\n",
       "      <td>0.170073</td>\n",
       "      <td>0.161772</td>\n",
       "      <td>0.154975</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003836</td>\n",
       "      <td>-0.004734</td>\n",
       "      <td>6.693594e+05</td>\n",
       "      <td>0.010055</td>\n",
       "      <td>1.315715</td>\n",
       "      <td>0.030237</td>\n",
       "      <td>5.235704e+04</td>\n",
       "      <td>-8.124241e+06</td>\n",
       "      <td>1.313372e+06</td>\n",
       "      <td>-1.000000e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155403</th>\n",
       "      <td>1746520665000000000</td>\n",
       "      <td>24387.5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.270770</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.173109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001037</td>\n",
       "      <td>0.003309</td>\n",
       "      <td>2.847738e+06</td>\n",
       "      <td>0.008796</td>\n",
       "      <td>0.648142</td>\n",
       "      <td>0.041674</td>\n",
       "      <td>3.459928e+05</td>\n",
       "      <td>-2.764208e+07</td>\n",
       "      <td>2.203250e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159498</th>\n",
       "      <td>1746591359000000000</td>\n",
       "      <td>24384.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.426385</td>\n",
       "      <td>0.396069</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.341066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035097</td>\n",
       "      <td>-0.030470</td>\n",
       "      <td>-3.629051e+06</td>\n",
       "      <td>0.146150</td>\n",
       "      <td>-8.941554</td>\n",
       "      <td>1.278703</td>\n",
       "      <td>6.211531e+06</td>\n",
       "      <td>7.623811e+06</td>\n",
       "      <td>-5.587995e+05</td>\n",
       "      <td>3.208558e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106693</th>\n",
       "      <td>1746165957000000000</td>\n",
       "      <td>24329.3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.196625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.002318</td>\n",
       "      <td>-1.051215e+06</td>\n",
       "      <td>0.026776</td>\n",
       "      <td>0.242156</td>\n",
       "      <td>0.025405</td>\n",
       "      <td>2.716713e+06</td>\n",
       "      <td>-3.698245e+06</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159879</th>\n",
       "      <td>1746591740000000000</td>\n",
       "      <td>24335.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.377406</td>\n",
       "      <td>0.349971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.256396</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008603</td>\n",
       "      <td>-0.004291</td>\n",
       "      <td>-1.986960e+06</td>\n",
       "      <td>0.012081</td>\n",
       "      <td>-1.567061</td>\n",
       "      <td>0.025376</td>\n",
       "      <td>-1.849046e+05</td>\n",
       "      <td>9.476678e+05</td>\n",
       "      <td>-8.574375e+05</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152103</th>\n",
       "      <td>1746517365000000000</td>\n",
       "      <td>24379.3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.281599</td>\n",
       "      <td>0.263384</td>\n",
       "      <td>0.241601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.149054</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009330</td>\n",
       "      <td>0.001730</td>\n",
       "      <td>3.085312e+05</td>\n",
       "      <td>-0.010100</td>\n",
       "      <td>0.017339</td>\n",
       "      <td>0.041731</td>\n",
       "      <td>-5.464379e+06</td>\n",
       "      <td>9.938785e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145579</th>\n",
       "      <td>1746510841000000000</td>\n",
       "      <td>24383.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.277396</td>\n",
       "      <td>0.256449</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.214142</td>\n",
       "      <td>0.191823</td>\n",
       "      <td>0.168970</td>\n",
       "      <td>0.146202</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006017</td>\n",
       "      <td>-0.014316</td>\n",
       "      <td>-5.171651e+05</td>\n",
       "      <td>0.009618</td>\n",
       "      <td>-0.905712</td>\n",
       "      <td>-0.035879</td>\n",
       "      <td>-5.117804e+05</td>\n",
       "      <td>-3.953448e+07</td>\n",
       "      <td>1.914297e+05</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171749</th>\n",
       "      <td>1746603610000000000</td>\n",
       "      <td>24348.2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.386717</td>\n",
       "      <td>0.355572</td>\n",
       "      <td>0.323200</td>\n",
       "      <td>0.296829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.190997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>0.003366</td>\n",
       "      <td>1.357577e+06</td>\n",
       "      <td>0.016415</td>\n",
       "      <td>0.766966</td>\n",
       "      <td>-0.016124</td>\n",
       "      <td>-9.293144e+05</td>\n",
       "      <td>6.414991e+06</td>\n",
       "      <td>3.323359e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170951</th>\n",
       "      <td>1746602812000000000</td>\n",
       "      <td>24369.2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.364037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.197596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016227</td>\n",
       "      <td>0.003816</td>\n",
       "      <td>-1.143805e+06</td>\n",
       "      <td>-0.078126</td>\n",
       "      <td>-4.805470</td>\n",
       "      <td>0.044012</td>\n",
       "      <td>5.879343e+05</td>\n",
       "      <td>1.164564e+07</td>\n",
       "      <td>1.869930e+05</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23753 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  timestamp  underlying  expiry  call_iv_23500  call_iv_23600  \\\n",
       "158881  1746590742000000000     24433.0       2       0.435793       0.409610   \n",
       "117518  1746176782000000000     24285.5       2            NaN            NaN   \n",
       "155403  1746520665000000000     24387.5       2            NaN       0.270770   \n",
       "159498  1746591359000000000     24384.6       2       0.426385       0.396069   \n",
       "106693  1746165957000000000     24329.3       2            NaN            NaN   \n",
       "...                     ...         ...     ...            ...            ...   \n",
       "159879  1746591740000000000     24335.0       2            NaN       0.377406   \n",
       "152103  1746517365000000000     24379.3       2       0.281599       0.263384   \n",
       "145579  1746510841000000000     24383.8       2       0.277396       0.256449   \n",
       "171749  1746603610000000000     24348.2       2       0.386717       0.355572   \n",
       "170951  1746602812000000000     24369.2       2            NaN       0.364037   \n",
       "\n",
       "        call_iv_23700  call_iv_23800  call_iv_23900  call_iv_24000  \\\n",
       "158881       0.383775       0.356050            NaN            NaN   \n",
       "117518       0.187751       0.178467       0.170073       0.161772   \n",
       "155403            NaN            NaN            NaN       0.173109   \n",
       "159498            NaN       0.341066            NaN            NaN   \n",
       "106693       0.196625            NaN            NaN            NaN   \n",
       "...               ...            ...            ...            ...   \n",
       "159879       0.349971            NaN            NaN       0.256396   \n",
       "152103       0.241601            NaN            NaN            NaN   \n",
       "145579            NaN       0.214142       0.191823       0.168970   \n",
       "171749       0.323200       0.296829            NaN            NaN   \n",
       "170951            NaN            NaN            NaN            NaN   \n",
       "\n",
       "        call_iv_24100  ...       X32       X33           X34       X35  \\\n",
       "158881            NaN  ... -0.022656  0.006262  2.553592e+06 -0.001931   \n",
       "117518       0.154975  ...  0.003836 -0.004734  6.693594e+05  0.010055   \n",
       "155403            NaN  ...  0.001037  0.003309  2.847738e+06  0.008796   \n",
       "159498       0.242813  ...  0.035097 -0.030470 -3.629051e+06  0.146150   \n",
       "106693            NaN  ...  0.001900  0.002318 -1.051215e+06  0.026776   \n",
       "...               ...  ...       ...       ...           ...       ...   \n",
       "159879            NaN  ...  0.008603 -0.004291 -1.986960e+06  0.012081   \n",
       "152103       0.149054  ... -0.009330  0.001730  3.085312e+05 -0.010100   \n",
       "145579       0.146202  ... -0.006017 -0.014316 -5.171651e+05  0.009618   \n",
       "171749       0.190997  ...  0.001378  0.003366  1.357577e+06  0.016415   \n",
       "170951       0.197596  ...  0.016227  0.003816 -1.143805e+06 -0.078126   \n",
       "\n",
       "             X36       X37           X38           X39           X40  \\\n",
       "158881  2.372125  0.068108 -1.522534e+06 -3.048516e+06  1.254699e+06   \n",
       "117518  1.315715  0.030237  5.235704e+04 -8.124241e+06  1.313372e+06   \n",
       "155403  0.648142  0.041674  3.459928e+05 -2.764208e+07  2.203250e+06   \n",
       "159498 -8.941554  1.278703  6.211531e+06  7.623811e+06 -5.587995e+05   \n",
       "106693  0.242156  0.025405  2.716713e+06 -3.698245e+06 -0.000000e+00   \n",
       "...          ...       ...           ...           ...           ...   \n",
       "159879 -1.567061  0.025376 -1.849046e+05  9.476678e+05 -8.574375e+05   \n",
       "152103  0.017339  0.041731 -5.464379e+06  9.938785e+06  0.000000e+00   \n",
       "145579 -0.905712 -0.035879 -5.117804e+05 -3.953448e+07  1.914297e+05   \n",
       "171749  0.766966 -0.016124 -9.293144e+05  6.414991e+06  3.323359e+04   \n",
       "170951 -4.805470  0.044012  5.879343e+05  1.164564e+07  1.869930e+05   \n",
       "\n",
       "                 X41  \n",
       "158881 -0.000000e+00  \n",
       "117518 -1.000000e-06  \n",
       "155403  0.000000e+00  \n",
       "159498  3.208558e+06  \n",
       "106693 -0.000000e+00  \n",
       "...              ...  \n",
       "159879 -0.000000e+00  \n",
       "152103  0.000000e+00  \n",
       "145579 -0.000000e+00  \n",
       "171749  0.000000e+00  \n",
       "170951 -0.000000e+00  \n",
       "\n",
       "[23753 rows x 97 columns]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "343b8046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['call_iv_23500',\n",
       " 'call_iv_23600',\n",
       " 'call_iv_23700',\n",
       " 'call_iv_23800',\n",
       " 'call_iv_23900',\n",
       " 'call_iv_24000',\n",
       " 'call_iv_24100',\n",
       " 'call_iv_24200',\n",
       " 'call_iv_24300',\n",
       " 'call_iv_24400',\n",
       " 'call_iv_24500',\n",
       " 'call_iv_24600',\n",
       " 'call_iv_24700',\n",
       " 'call_iv_24800',\n",
       " 'call_iv_24900',\n",
       " 'call_iv_25000',\n",
       " 'call_iv_25100',\n",
       " 'call_iv_25200',\n",
       " 'call_iv_25300',\n",
       " 'call_iv_25400',\n",
       " 'call_iv_25500',\n",
       " 'call_iv_25600',\n",
       " 'call_iv_25700',\n",
       " 'call_iv_25800',\n",
       " 'call_iv_25900',\n",
       " 'call_iv_26000']"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_cols = [col for col in train_data.columns if col.startswith('call') and col in test_data.columns]\n",
    "common_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "299fcf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import root_mean_squared_error as rmse\n",
    "\n",
    "\n",
    "def train_xgb(given_df, col1, col2):\n",
    "    # -----------------------------\n",
    "    # Step 1: Setup\n",
    "    # -----------------------------\n",
    "    # Define your target\n",
    "    target_col = col2\n",
    "\n",
    "    # Add additional features\n",
    "    feature_cols = [col1 ]+ [\"underlying\", \"expiry\"]  # Add more if available\n",
    "\n",
    "    # -----------------------------\n",
    "    # Step 2: Prepare Training Data\n",
    "    # -----------------------------\n",
    "    # Drop rows with NaN in any input or the target\n",
    "    given_df = given_df[feature_cols + [target_col]].dropna()\n",
    "\n",
    "    X = given_df[feature_cols]\n",
    "    y = given_df[target_col]\n",
    "\n",
    "    # Optional: Normalize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Step 3: Train XGBoost Regressor\n",
    "    # -----------------------------\n",
    "    xgb_model = XGBRegressor(\n",
    "        n_estimators=800,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.9,\n",
    "        random_state=43,\n",
    "    )\n",
    "\n",
    "    xgb_model.fit(X_scaled, y)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Step 4: Predict in Test Data\n",
    "    # -----------------------------\n",
    "    # Test: Make sure underlying and IVs (except target) are available\n",
    "    test_data = val_Y[feature_cols].copy()\n",
    "    test_data_scaled = scaler.transform(test_data)\n",
    "\n",
    "    # Predict target column\n",
    "    predicted_call_iv_25000 = xgb_model.predict(test_data_scaled)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Step 5: Impute into Test DataFrame\n",
    "    # -----------------------------\n",
    "    test_imputed = sample_val.copy()\n",
    "    missing_mask = test_imputed[target_col].isna()\n",
    "    test_imputed.loc[missing_mask, target_col] = predicted_call_iv_25000[missing_mask]\n",
    "    print(col2, rmse(val_Y[target_col], test_imputed[target_col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "80f1d32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call_iv_23600 0.0019634675273223702\n",
      "call_iv_23700 0.001617209676355377\n",
      "call_iv_23800 0.0011148703205429453\n",
      "call_iv_23900 0.0008918749699855635\n",
      "call_iv_24000 0.0007911677166453678\n",
      "call_iv_24100 0.0015873125821282662\n",
      "call_iv_24200 0.0011683634481923371\n",
      "call_iv_24300 0.002064869919112093\n",
      "call_iv_24400 0.001039063169097482\n",
      "call_iv_24500 0.0013106320889633184\n",
      "call_iv_24600 0.0018321202596570658\n",
      "call_iv_24700 0.0009481653714509304\n",
      "call_iv_24800 0.0007197158958654638\n",
      "call_iv_24900 0.0014947660925306674\n",
      "call_iv_25000 0.0008678682288392795\n",
      "call_iv_25100 0.0006459108472106488\n",
      "call_iv_25200 0.0004970628666050636\n",
      "call_iv_25300 0.00043788584321932824\n",
      "call_iv_25400 0.0005733690518143546\n",
      "call_iv_25500 0.0006475355415838873\n",
      "call_iv_25600 0.0006518079474414109\n",
      "call_iv_25700 0.0005980948522618613\n",
      "call_iv_25800 0.0005668770017225137\n",
      "call_iv_25900 0.0006245723634674341\n",
      "call_iv_26000 0.0007521968334968915\n"
     ]
    }
   ],
   "source": [
    "for i in range(common_cols.__len__()-1):\n",
    "    train_xgb(train_data, common_cols[i], common_cols[i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "e9c53db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_parquet(\"../data/test_data.parquet\")\n",
    "common_cols = [col for col in train_data.columns if (col.startswith('call') or col.startswith('put')) and col in test_data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "b66cf1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputed 0 NaN values in call_iv_23500 with median: 0.30767049999999996\n",
      "Imputed 0 NaN values in call_iv_23600 with median: 0.286101\n",
      "Imputed 0 NaN values in call_iv_23700 with median: 0.2657875\n",
      "Imputed 0 NaN values in call_iv_23800 with median: 0.244635\n",
      "Imputed 0 NaN values in call_iv_23900 with median: 0.22357349999999998\n",
      "Imputed 0 NaN values in call_iv_24000 with median: 0.1987605\n",
      "Imputed 0 NaN values in call_iv_26000 with median: 0.342125\n",
      "Imputed 0 NaN values in put_iv_24300 with median: 0.143855\n",
      "Imputed 0 NaN values in put_iv_24600 with median: 0.15524149999999998\n",
      "Imputed 0 NaN values in put_iv_24800 with median: 0.18014\n",
      "Imputed 0 NaN values in put_iv_24900 with median: 0.188084\n",
      "Imputed 0 NaN values in put_iv_25000 with median: 0.191225\n",
      "Remaining NaN values in train_data: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_20376\\3160474084.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_20376\\3160474084.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_20376\\3160474084.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_20376\\3160474084.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_20376\\3160474084.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_20376\\3160474084.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_20376\\3160474084.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_20376\\3160474084.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_20376\\3160474084.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_20376\\3160474084.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_20376\\3160474084.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data[col].fillna(median_val, inplace=True)\n",
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_20376\\3160474084.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_data[col].fillna(median_val, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Impute median for NaN values in train_data\n",
    "for col in train_data.columns:\n",
    "  if train_data[col].dtype in ['float64', 'int64'] and train_data[col].isna().any():\n",
    "    median_val = train_data[col].median()\n",
    "    train_data[col].fillna(median_val, inplace=True)\n",
    "    print(f\"Imputed {train_data[col].isna().sum()} NaN values in {col} with median: {median_val}\")\n",
    "\n",
    "print(f\"Remaining NaN values in train_data: {train_data.isna().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abca1fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "315"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb339a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Load your data (modify paths as needed)\\ntrain_data = pd.read_parquet(\"../data/train_data.parquet\")\\nval_Y = pd.read_parquet(\"val_Y.parquet\")\\n\\n# Define common columns\\ncommon_cols = [col for col in train_data.columns if col.startswith(\\'call\\') and col in val_Y.columns]\\n\\n# Train models with grid search (this will take longer but give better results)\\nresults_with_gridsearch = train_all_strikes_with_gridsearch(\\n    train_data, val_Y, common_cols, use_gridsearch=True\\n)\\n\\n# Create summary report\\nsummary = create_summary_report(results_with_gridsearch)\\n\\n# Save models (optional)\\nsave_models(results_with_gridsearch, \"optimized_xgb_models\")\\n\\n# For faster training without grid search:\\n# results_fast = train_all_strikes_with_gridsearch(\\n#     train_data, val_Y, common_cols, use_gridsearch=False\\n# )\\n'"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import root_mean_squared_error as rmse\n",
    "from alive_progress import alive_bar\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def train_xgb_with_gridsearch(given_df, col1, col2, use_gridsearch=True, verbose=True):\n",
    "    \"\"\"\n",
    "    Train XGBoost model with optional grid search for hyperparameter optimization\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    given_df : DataFrame\n",
    "        Training data\n",
    "    col1 : str\n",
    "        Input IV column (previous strike)\n",
    "    col2 : str\n",
    "        Target IV column (current strike)\n",
    "    use_gridsearch : bool\n",
    "        Whether to perform grid search for hyperparameter tuning\n",
    "    verbose : bool\n",
    "        Whether to print detailed results\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Contains model, scaler, parameters, and performance metrics\n",
    "    \"\"\"\n",
    "\n",
    "    # Setup\n",
    "    target_col = col2\n",
    "    feature_cols = [col1] + [\"underlying\", \"expiry\"]\n",
    "\n",
    "    # Prepare training data - drop rows with NaN\n",
    "    train_clean = given_df[feature_cols + [target_col]].dropna()\n",
    "\n",
    "    if len(train_clean) == 0:\n",
    "        if verbose:\n",
    "            print(f\"Warning: No valid training data for {col2}\")\n",
    "        return None\n",
    "\n",
    "    X = train_clean[feature_cols]\n",
    "    y = train_clean[target_col]\n",
    "\n",
    "    # Normalize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Split for validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_scaled, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    if use_gridsearch:\n",
    "        # Define parameter grid for grid search\n",
    "        param_grid = {\n",
    "            \"n_estimators\": [300, 500, 800],\n",
    "            \"learning_rate\": [0.05, 0.1, 0.15],\n",
    "            \"max_depth\": [4, 6, 8],\n",
    "            \"subsample\": [0.8, 0.9, 1.0],\n",
    "            # \"colsample_bytree\": [0.8, 0.9, 1.0],\n",
    "            # \"reg_alpha\": [0, 0.1, 0.5],\n",
    "            # \"reg_lambda\": [1, 1.5, 2],\n",
    "        }\n",
    "\n",
    "        # Create base XGBoost model\n",
    "        xgb_base = XGBRegressor(random_state=42, n_jobs=-1, verbosity=0)\n",
    "\n",
    "        # Setup cross-validation\n",
    "        cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "        # Perform grid search\n",
    "        if verbose:\n",
    "            print(f\"Performing grid search for {col2}...\")\n",
    "\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=xgb_base,\n",
    "            param_grid=param_grid,\n",
    "            cv=cv,\n",
    "            scoring=\"neg_root_mean_squared_error\",\n",
    "            n_jobs=-1,\n",
    "            verbose=0,\n",
    "        )\n",
    "\n",
    "        # Fit grid search\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # Get best model\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "\n",
    "    else:\n",
    "        # Use default parameters\n",
    "        best_params = {\n",
    "            \"n_estimators\": 800,\n",
    "            \"learning_rate\": 0.1,\n",
    "            \"max_depth\": 6,\n",
    "            \"subsample\": 0.9,\n",
    "            \"colsample_bytree\": 1.0,\n",
    "            \"reg_alpha\": 0,\n",
    "            \"reg_lambda\": 1,\n",
    "        }\n",
    "\n",
    "        best_model = XGBRegressor(\n",
    "            **best_params, random_state=42, n_jobs=-1, verbosity=0\n",
    "        )\n",
    "\n",
    "        best_model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on validation set\n",
    "    y_pred_val = best_model.predict(X_val)\n",
    "\n",
    "    # Calculate metrics\n",
    "    rmse_score = rmse(y_val, y_pred_val)\n",
    "    r2 = r2_score(y_val, y_pred_val)\n",
    "\n",
    "    # Predict on test data (val_Y)\n",
    "    test_data = val_Y[feature_cols].copy()\n",
    "    test_data_scaled = scaler.transform(test_data)\n",
    "    predicted_values = best_model.predict(test_data_scaled)\n",
    "\n",
    "    # Calculate test RMSE if ground truth is available\n",
    "    test_rmse = rmse(val_Y[target_col], predicted_values)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\n=== Results for {col2} ===\")\n",
    "        print(f\"Training samples: {len(train_clean)}\")\n",
    "        print(f\"Validation RMSE: {rmse_score:.6f}\")\n",
    "        print(f\"Validation R²: {r2:.6f}\")\n",
    "        print(f\"Test RMSE: {test_rmse:.6f}\")\n",
    "        if use_gridsearch:\n",
    "            print(f\"Best parameters: {best_params}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    return {\n",
    "        \"model\": best_model,\n",
    "        \"scaler\": scaler,\n",
    "        \"best_params\": best_params,\n",
    "        \"validation_rmse\": rmse_score,\n",
    "        \"validation_r2\": r2,\n",
    "        \"test_rmse\": test_rmse,\n",
    "        \"predictions\": predicted_values,\n",
    "        \"feature_cols\": feature_cols,\n",
    "        \"target_col\": target_col,\n",
    "    }\n",
    "\n",
    "\n",
    "def train_all_strikes_with_gridsearch(\n",
    "    train_data, val_Y, common_cols, use_gridsearch=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Train XGBoost models for all strike prices with grid search optimization\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    train_data : DataFrame\n",
    "        Training dataset\n",
    "    val_Y : DataFrame\n",
    "        Validation/test dataset with ground truth\n",
    "    common_cols : list\n",
    "        List of call IV column names\n",
    "    use_gridsearch : bool\n",
    "        Whether to use grid search for hyperparameter optimization\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary containing results for each strike price\n",
    "    \"\"\"\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    print(f\"Training models for {len(common_cols)-1} strike pairs...\")\n",
    "    print(f\"Grid search: {'Enabled' if use_gridsearch else 'Disabled'}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    with alive_bar(len(common_cols) - 1) as bar:\n",
    "        for i in range(len(common_cols) - 1):\n",
    "            col1 = common_cols[i]  # Input IV (previous strike)\n",
    "            col2 = common_cols[i + 1]  # Target IV (next strike)\n",
    "\n",
    "            try:\n",
    "                result = train_xgb_with_gridsearch(\n",
    "                    train_data,\n",
    "                    col1,\n",
    "                    col2,\n",
    "                    use_gridsearch=use_gridsearch,\n",
    "                    verbose=False,  # Set to True for detailed output\n",
    "                )\n",
    "\n",
    "                if result is not None:\n",
    "                    results[col2] = result\n",
    "                    print(f\"{col2}: Test RMSE = {result['test_rmse']:.6f}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error training model for {col2}: {str(e)}\")\n",
    "\n",
    "            bar()\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def create_summary_report(results):\n",
    "    \"\"\"\n",
    "    Create a summary report of all model results\n",
    "    \"\"\"\n",
    "    if not results:\n",
    "        print(\"No results to summarize\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"SUMMARY REPORT - XGBoost Models with Grid Search\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Create summary DataFrame\n",
    "    summary_data = []\n",
    "    for strike, result in results.items():\n",
    "        summary_data.append(\n",
    "            {\n",
    "                \"Strike\": strike,\n",
    "                \"Val_RMSE\": result[\"validation_rmse\"],\n",
    "                \"Val_R2\": result[\"validation_r2\"],\n",
    "                \"Test_RMSE\": result[\"test_rmse\"],\n",
    "                \"N_Estimators\": result[\"best_params\"][\"n_estimators\"],\n",
    "                \"Learning_Rate\": result[\"best_params\"][\"learning_rate\"],\n",
    "                \"Max_Depth\": result[\"best_params\"][\"max_depth\"],\n",
    "                \"Subsample\": result[\"best_params\"][\"subsample\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "    print(f\"\\nOverall Performance:\")\n",
    "    print(f\"Average Test RMSE: {summary_df['Test_RMSE'].mean():.6f}\")\n",
    "    print(\n",
    "        f\"Best Test RMSE: {summary_df['Test_RMSE'].min():.6f} ({summary_df.loc[summary_df['Test_RMSE'].idxmin(), 'Strike']})\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Worst Test RMSE: {summary_df['Test_RMSE'].max():.6f} ({summary_df.loc[summary_df['Test_RMSE'].idxmax(), 'Strike']})\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\nDetailed Results:\")\n",
    "    print(summary_df.to_string(index=False, float_format=\"%.6f\"))\n",
    "\n",
    "    return summary_df\n",
    "\n",
    "\n",
    "def save_models(results, filepath_prefix=\"xgb_models\"):\n",
    "    \"\"\"\n",
    "    Save trained models and scalers to files\n",
    "    \"\"\"\n",
    "    import pickle\n",
    "\n",
    "    for strike, result in results.items():\n",
    "        # Save model\n",
    "        model_path = f\"{filepath_prefix}_{strike}_model.pkl\"\n",
    "        with open(model_path, \"wb\") as f:\n",
    "            pickle.dump(result[\"model\"], f)\n",
    "\n",
    "        # Save scaler\n",
    "        scaler_path = f\"{filepath_prefix}_{strike}_scaler.pkl\"\n",
    "        with open(scaler_path, \"wb\") as f:\n",
    "            pickle.dump(result[\"scaler\"], f)\n",
    "\n",
    "    print(f\"Saved {len(results)} models and scalers with prefix '{filepath_prefix}'\")\n",
    "\n",
    "\n",
    "# Example usage (assuming your data is already loaded):\n",
    "# Uncomment and modify these lines based on your actual data setup\n",
    "\n",
    "\"\"\"\n",
    "# Load your data (modify paths as needed)\n",
    "train_data = pd.read_parquet(\"../data/train_data.parquet\")\n",
    "val_Y = pd.read_parquet(\"val_Y.parquet\")\n",
    "\n",
    "# Define common columns\n",
    "common_cols = [col for col in train_data.columns if col.startswith('call') and col in val_Y.columns]\n",
    "\n",
    "# Train models with grid search (this will take longer but give better results)\n",
    "results_with_gridsearch = train_all_strikes_with_gridsearch(\n",
    "    train_data, val_Y, common_cols, use_gridsearch=True\n",
    ")\n",
    "\n",
    "# Create summary report\n",
    "summary = create_summary_report(results_with_gridsearch)\n",
    "\n",
    "# Save models (optional)\n",
    "save_models(results_with_gridsearch, \"optimized_xgb_models\")\n",
    "\n",
    "# For faster training without grid search:\n",
    "# results_fast = train_all_strikes_with_gridsearch(\n",
    "#     train_data, val_Y, common_cols, use_gridsearch=False\n",
    "# )\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "f47ef79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training models for 41 strike pairs...\n",
      "Grid search: Enabled\n",
      "============================================================\n",
      "|⚠︎                                       | (!) 0/41 [0%] in 37:54.2 (0.00/s) \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[242], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m results_optimized \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_all_strikes_with_gridsearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_Y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommon_cols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_gridsearch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m      3\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Create summary report\u001b[39;00m\n\u001b[0;32m      6\u001b[0m summary \u001b[38;5;241m=\u001b[39m create_summary_report(results_optimized)\n",
      "Cell \u001b[1;32mIn[241], line 189\u001b[0m, in \u001b[0;36mtrain_all_strikes_with_gridsearch\u001b[1;34m(train_data, val_Y, common_cols, use_gridsearch)\u001b[0m\n\u001b[0;32m    186\u001b[0m col2 \u001b[38;5;241m=\u001b[39m common_cols[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Target IV (next strike)\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 189\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_xgb_with_gridsearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcol1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcol2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_gridsearch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_gridsearch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Set to True for detailed output\u001b[39;49;00m\n\u001b[0;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    198\u001b[0m         results[col2] \u001b[38;5;241m=\u001b[39m result\n",
      "Cell \u001b[1;32mIn[241], line 93\u001b[0m, in \u001b[0;36mtrain_xgb_with_gridsearch\u001b[1;34m(given_df, col1, col2, use_gridsearch, verbose)\u001b[0m\n\u001b[0;32m     83\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[0;32m     84\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mxgb_base,\n\u001b[0;32m     85\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mparam_grid,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     89\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m     90\u001b[0m )\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# Fit grid search\u001b[39;00m\n\u001b[1;32m---> 93\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;66;03m# Get best model\u001b[39;00m\n\u001b[0;32m     96\u001b[0m best_model \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[1;32mc:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1527\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1526\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1527\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[1;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1707\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results_optimized = train_all_strikes_with_gridsearch(\n",
    "    train_data, val_Y, common_cols, use_gridsearch=True\n",
    ")\n",
    "\n",
    "# Create summary report\n",
    "summary = create_summary_report(results_optimized)\n",
    "\n",
    "# Save models for later use\n",
    "save_models(results_optimized, \"optimized_xgb_models\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
